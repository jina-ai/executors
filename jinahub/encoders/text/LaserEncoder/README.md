# LaserEncoder

**LaserEncoder** is a encoder based on Facebook Research's LASER (Language-Agnostic SEntence Representations) to compute multilingual sentence embeddings.

It encodes `Document` content from an 1d array of string in size `B` into an ndarray in size `B x D`.

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**

- [ğŸŒ± Prerequisites](#-prerequisites)
- [ğŸš€ Usages](#-usages)
- [ğŸ‰ï¸ Example](#%EF%B8%8F-example)
- [ğŸ”ï¸ Reference](#%EF%B8%8F-reference)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

## ğŸŒ± Prerequisites


> These are only needed if you download the source code and directly use the class. Not needed if you use the Jina Hub method below.

```bash
python -m laserembeddings download-models
```

To install the dependencies locally run 
```
pip install . 
pip install -r tests/requirements.txt
```
To verify the installation works:
```
pytest tests
```

## ğŸš€ Usages

### ğŸšš Via JinaHub

#### using docker images
Use the prebuilt images from JinaHub in your Python codes. The input language can be configured with `language`. The full list of possible values can be found at [LASER](https://github.com/facebookresearch/LASER#supported-languages) with the language code ([ISO 639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)) 

```python
from jina import Flow
	
f = Flow().add(uses='jinahub+docker://laser-encoder', override_with={'language': 'en'})
```

or in the `.yml` config.
	
```yaml
jtype: Flow
pods:
  - name: encoder
    uses: 'jinahub+docker://laser-encoder'
```

#### using source code
Use the source code from JinaHub in your Python code:

```python
from jina import Flow
	
f = Flow().add(uses='jinahub://laser-encoder')
```

or in the `.yml` config.

```yaml
jtype: Flow
pods:
  - name: encoder
    uses: 'jinahub://laser-encoder'
```
DETAILSSTART
